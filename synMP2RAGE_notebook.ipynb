{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "synMP2RAGE_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-oKarfdLF-T",
        "colab_type": "text"
      },
      "source": [
        "##Attribution and license\n",
        "\n",
        "Portions of this page are modifications based on work created and shared by Google and used according to terms described in the Creative Commons 4.0 Attribution License. Code samples are licensed under the Apache 2.0 License. For the original page refer to\n",
        " https://www.tensorflow.org/tutorials/generative/pix2pix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIfR8QdySphk",
        "colab_type": "text"
      },
      "source": [
        "##Import and install required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YfIk2es3hJEd",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import time\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython import display\n",
        "import numpy as np\n",
        "from nibabel import load as load_nii\n",
        "import nibabel as nib\n",
        "from skimage.transform import resize\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wifwThPoEj7e",
        "colab": {}
      },
      "source": [
        "!pip install -U tensorboard\n",
        "!nvidia-smi\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0j5UhGCOxHX",
        "colab_type": "text"
      },
      "source": [
        "## Loading training data\n",
        "*Both MPRAGE and MP2RAGE images need to be previously skull-stripped\n",
        "\n",
        "*All the 2D slices of each subject are loaded in a TF dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HsktC73FE7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(path):\n",
        "    m_image = load_nii((path+'mprage_sk.nii.gz'),mmap=True)\n",
        "    image = np.float32(m_image.get_fdata())\n",
        "    m_gt = load_nii((path+'mp2rage_sk.nii.gz'),mmap=True)\n",
        "    gt = np.float32(m_gt.get_fdata())\n",
        "\n",
        "    ind = (np.where(image>0))\n",
        "    x2 = (np.max(ind[0]))\n",
        "    x1 = (np.min(ind[0]))\n",
        "    y2 = (np.max(ind[1]))\n",
        "    y1 = (np.min(ind[1]))\n",
        "    z2 = (np.max(ind[2]))\n",
        "    z1 = (np.min(ind[2]))\n",
        "\n",
        "    z_dim = np.shape(np.squeeze(image))[2]\n",
        "    n_images = (x2-x1)+(y2-y1)+(z2-z1)\n",
        "    inp = np.zeros([n_images,150,150,1])\n",
        "    t = np.zeros([n_images,150,150,1])\n",
        "\n",
        "    gt[(gt>3400)]= 2000\n",
        "    gt[(gt>2500) & (image<150)]= 2000\n",
        "\n",
        "    image -= np.mean(image)\n",
        "    image /= np.std(image)\n",
        "    gt -= np.mean(gt)\n",
        "    gt /= np.std(gt)\n",
        "\n",
        "    for i in range(z1,z2):\n",
        "\n",
        "        image_one = image[x1:(x1+150),y1:(y1+150), i]\n",
        "        gt_one = gt[x1:(x1+150),y1:(y1+150), i]\n",
        "        image_one=np.expand_dims(image_one,axis=2)\n",
        "        gt_one=np.expand_dims(gt_one,axis=2)\n",
        "        inp[i-z1,:,:,:]=image_one\n",
        "        t[i-z1,:,:,:]=gt_one\n",
        "\n",
        "    for i in range(y1,y2):\n",
        "        image_one = np.squeeze(image[x1:(x1+150),i,:150])\n",
        "        gt_one = np.squeeze(gt[x1:(x1+150),i,:150])\n",
        "        image_one=np.expand_dims(image_one,axis=2)\n",
        "        gt_one=np.expand_dims(gt_one,axis=2)\n",
        "        inp[(z2-z1)+i-y1,:240,:z_dim,:]=image_one\n",
        "        t[(z2-z1)+i-y1,:240,:z_dim,:]=gt_one\n",
        "        \n",
        "    for i in range(x1,x2):\n",
        "\n",
        "        image_one = np.squeeze(image[i,y1:(y1+150),:150])\n",
        "        gt_one = np.squeeze(gt[i,y1:(y1+150),:150])\n",
        "        image_one=np.expand_dims(image_one,axis=2)\n",
        "        gt_one=np.expand_dims(gt_one,axis=2)\n",
        "        inp[(z2-z1+y2-y1)+i-x1,:256,:z_dim,:]=image_one\n",
        "        t[(z2-z1+y2-y1)+i-x1,:256,:z_dim,:]=gt_one\n",
        "\n",
        "    return inp,t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc2LBqAEPSWl",
        "colab_type": "text"
      },
      "source": [
        "The variable path refers to the folder containing the training dataset. Each subject needs a subfolder named 1 to N, where N is the total number of training subjects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWp2SygA4FxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '../Data/' \n",
        "N= 20\n",
        "\n",
        "x,y =load_data(path+str(1)+'/')\n",
        "for i in range (2,N):\n",
        "  x2,y2 =load_data(path+str(i)+'/')\n",
        "  assert x2.shape[0] == y2.shape[0]\n",
        "  x = np.concatenate((x,x2))\n",
        "  y = np.concatenate((y,y2))\n",
        "print(np.shape(x))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9sIAC4LPvD0",
        "colab_type": "text"
      },
      "source": [
        "Optional: applying bias field data augmentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyRBfMUeqpZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bias_field(image):\n",
        "  image=np.squeeze(image)\n",
        "  \n",
        "  r = np.random.random(1)[0]\n",
        "  p = np.random.random(1)[0]\n",
        "  image2=np.zeros_like(image)\n",
        "\n",
        "  if p<0.25:\n",
        "    for i in range(0,image.shape[0]):\n",
        "      for k in range(0,image.shape[1]):\n",
        "        image2[i,k]=image[i,k]+(i*r*0.001)\n",
        "  if p>0.25 and p<0.50:\n",
        "    for i in range(0,image.shape[0]):\n",
        "      for k in range(0,image.shape[1]):\n",
        "        image2[i,k]=image[i,k]+((image.shape[0]-i)*r*0.001)\n",
        "  if p>0.50 and p<0.75:\n",
        "    for i in range(0,image.shape[1]):\n",
        "      for k in range(0,image.shape[0]):\n",
        "        image2[i,k]=image[i,k]+(i*r*0.001)\n",
        "  if p>0.75:\n",
        "    for i in range(0,image.shape[1]):\n",
        "      for k in range(0,image.shape[0]):\n",
        "        image2[i,k]=image[i,k]+((image.shape[1]-i)*r*0.001)         \n",
        "\n",
        "  image2=np.expand_dims(image2,0)\n",
        "  image2=np.expand_dims(image2,-1)\n",
        "\n",
        "  return image2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1m5-xjHyfQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crop(image,label):\n",
        "  \n",
        "  p = tf.random.uniform([1])\n",
        "  if p<0.5:\n",
        "    image = tf.image.random_crop(image, [1,128,128,1], seed=1)\n",
        "    label = tf.image.random_crop(label, [1,128,128,1], seed=1)\n",
        "    image= tf.image.random_flip_up_down(image,seed=1)\n",
        "    label= tf.image.random_flip_up_down(label,seed=1)\n",
        "\n",
        "  if p>0.5:\n",
        "    image = tf.image.random_crop(image, [1,64,64,1], seed=1)\n",
        "    label = tf.image.random_crop(label, [1,64,64,1], seed=1)\n",
        "    image= tf.image.resize(image,[128,128])\n",
        "    label= tf.image.resize(label,[128,128])\n",
        "    image= tf.image.random_flip_left_right(image, seed=1)\n",
        "    label= tf.image.random_flip_left_right(label, seed=1)\n",
        "\n",
        "  return image,label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvLeOVfrFOXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = np.shape(x)[0]\n",
        "BATCH_SIZE = 1\n",
        "IMG_WIDTH = 150\n",
        "IMG_HEIGHT = 150\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x.astype(np.float32), y.astype(np.float32)))\n",
        "train_dataset= train_dataset.shuffle(BUFFER_SIZE,reshuffle_each_iteration=True)\n",
        "train_dataset= train_dataset.batch(BATCH_SIZE)\n",
        "train_dataset = train_dataset.map(crop)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypnFYO6XP5Jk",
        "colab_type": "text"
      },
      "source": [
        "Plotting 10 examples of training images loaded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCGyKSkKwE_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_images(test_input, tar):\n",
        "  plt.figure(figsize=(15,15))\n",
        "  display_list = [np.squeeze(test_input[0]), np.squeeze(tar[0]) ]\n",
        "  title = ['Input Image', 'Ground Truth']\n",
        "\n",
        "  for i in range(2):\n",
        "    plt.subplot(1, 5, i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(display_list[i][:,:],cmap='gray')\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S2djQKrwUew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for example_input, example_target in train_dataset.take(10):\n",
        "  plot_images(example_input,example_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNtRF776Flpd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del x,y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "THY-sZMiQ4UV"
      },
      "source": [
        "## Build the Generator\n",
        "  * The architecture of the generator is a modified U-Net wtih residual blocks.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tqqvWxlw8b4l",
        "colab": {}
      },
      "source": [
        "OUTPUT_CHANNELS = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQwS9vKO3247",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def res_block(x,filters,filters2, size, apply_batchnorm=False):\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "  conv1 = tf.keras.layers.Conv2D(filters, size, strides=1, padding='same',\n",
        "                             kernel_initializer=initializer, use_bias=False) (x)\n",
        "  if apply_batchnorm:\n",
        "    conv1= tf.keras.layers.BatchNormalization() (conv1)\n",
        "  conv1= tf.keras.layers.LeakyReLU()(conv1) \n",
        "  \n",
        "  conv2 = tf.keras.layers.Conv2D(filters, size, strides=1, padding='same',\n",
        "                             kernel_initializer=initializer, use_bias=False) (conv1)\n",
        "  if apply_batchnorm:\n",
        "    conv2= tf.keras.layers.BatchNormalization() (conv2)\n",
        "  \n",
        "  conv2=tf.keras.layers.add([x,conv2])\n",
        "  conv2= tf.keras.layers.LeakyReLU()(conv2)\n",
        "\n",
        "  return conv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O71IJYbOoSpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def res_block_down(x,filters,filters2, size, apply_batchnorm=False):\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "  conv1 = tf.keras.layers.Conv2D(filters, size, strides=1, padding='same',\n",
        "                             kernel_initializer=initializer, use_bias=False) (x)\n",
        "  if apply_batchnorm:\n",
        "    conv1= tf.keras.layers.BatchNormalization() (conv1)\n",
        "  conv1= tf.keras.layers.LeakyReLU()(conv1) \n",
        "  \n",
        "  conv2 = tf.keras.layers.Conv2D(filters, size, strides=1, padding='same',\n",
        "                             kernel_initializer=initializer, use_bias=False) (conv1)\n",
        "  if apply_batchnorm:\n",
        "    conv2= tf.keras.layers.BatchNormalization() (conv2)\n",
        "  \n",
        "  conv2=tf.keras.layers.add([x,conv2])\n",
        "  conv2= tf.keras.layers.LeakyReLU()(conv2)\n",
        "\n",
        "  conv3 = tf.keras.layers.Conv2D(filters2, size, strides=2, padding='same',\n",
        "                             kernel_initializer=initializer, use_bias=False) (conv2)\n",
        "  if apply_batchnorm:\n",
        "    conv3= tf.keras.layers.BatchNormalization() (conv3)\n",
        "\n",
        "  conv3= tf.keras.layers.LeakyReLU()(conv3)\n",
        "\n",
        "  return conv3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dncOogis6vB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def res_block_up(x,x1,filters,filters2, size, apply_batchnorm=False, concat=True):\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "  if concat:\n",
        "    x = tf.keras.layers.Concatenate()([x,x1])\n",
        "  \n",
        "  conv1 = tf.keras.layers.Conv2D(filters, size, strides=1, padding='same',\n",
        "                             kernel_initializer=initializer, use_bias=False) (x)\n",
        "  if apply_batchnorm:\n",
        "    conv1= tf.keras.layers.BatchNormalization() (conv1)\n",
        "  conv1= tf.keras.layers.LeakyReLU()(conv1) \n",
        "  \n",
        "  conv2 = tf.keras.layers.Conv2D(filters, size, strides=1, padding='same',\n",
        "                             kernel_initializer=initializer, use_bias=False) (conv1)\n",
        "  if apply_batchnorm:\n",
        "    conv2= tf.keras.layers.BatchNormalization() (conv2)\n",
        "  \n",
        "  conv2=tf.keras.layers.add([conv1,conv2])\n",
        "  conv2= tf.keras.layers.LeakyReLU()(conv2)\n",
        "\n",
        "  conv3 = tf.keras.layers.Conv2DTranspose(filters2, size, strides=2, padding='same',\n",
        "                             kernel_initializer=initializer, use_bias=False)(conv2)\n",
        "\n",
        "  if apply_batchnorm:\n",
        "    conv3= tf.keras.layers.BatchNormalization() (conv3)\n",
        "\n",
        "  conv3= tf.keras.layers.LeakyReLU()(conv3)\n",
        "\n",
        "  return conv3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKhgY7HG8fpt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Generator():\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "  inputs = tf.keras.layers.Input(shape=[128,128,OUTPUT_CHANNELS])\n",
        "\n",
        "  down1 = res_block_down(inputs,32,64, 4) \n",
        "  down2 = res_block_down(down1,64,128, 4) \n",
        "  down3 = res_block_down(down2,128,256, 4) \n",
        "  down4 = res_block_down(down3,256,512, 4) \n",
        "  down5 = res_block_down(down4,512,512, 4) \n",
        "\n",
        "\n",
        "  tra1 = res_block(down5,512,512, 4)\n",
        "  tra2 = res_block(tra1,512,512, 4)\n",
        "  tra3 = res_block(tra2,512,512, 4)\n",
        "  tra4 = res_block(tra3,512,512, 4)\n",
        "\n",
        "  up7 = res_block_up(tra4,tra4,512,256, 4, False,False)\n",
        "  up3 = res_block_up(up7,down4,256,128, 4, False)\n",
        "  up2 = res_block_up(up3,down3,128,64 ,4)\n",
        "  up1 = res_block_up(up2,down2,64,32, 4)\n",
        "  up0 = res_block_up(up1,down1,32,32, 4)\n",
        "\n",
        "  \n",
        "  last = tf.keras.layers.Conv2D(OUTPUT_CHANNELS, 3,\n",
        "                                         strides=1,\n",
        "                                         padding='same',\n",
        "                                         kernel_initializer=initializer,\n",
        "                                         activation='tanh') (up0)\n",
        "\n",
        "  o = tf.math.add(inputs,last)\n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=o)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9BQWLIJw0C1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = Generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cyhxTuvJyIHV",
        "colab": {}
      },
      "source": [
        "LAMBDA = 150\n",
        "PHI= 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "90BIcCKcDMxz",
        "colab": {}
      },
      "source": [
        "def generator_loss(disc_generated_output, gen_output, target,vgg_loss):\n",
        "  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
        "  l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
        "  total_gen_loss =  gan_loss + (LAMBDA * l1_loss) + (PHI*vgg_loss)\n",
        " \n",
        "  return total_gen_loss, gan_loss, l1_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHXZl7x3QG9m",
        "colab_type": "text"
      },
      "source": [
        "## Build the Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAP0r42YU8D_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Discriminator():\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "  inp = tf.keras.layers.Input(shape=[128, 128, 1], name='input_image')\n",
        "  tar = tf.keras.layers.Input(shape=[128, 128, 1], name='target_image')\n",
        "\n",
        "  x = tf.keras.layers.concatenate([inp, tar]) \n",
        "\n",
        "  conv1 = tf.keras.layers.Conv2D(32, 4, strides=4,\n",
        "                                kernel_initializer=initializer)(x) \n",
        "  conv1 = tf.keras.layers.LeakyReLU()(conv1)\n",
        "  conv2 = tf.keras.layers.Conv2D(32, 4, strides=2,\n",
        "                                kernel_initializer=initializer)(conv1) \n",
        "  conv2 = tf.keras.layers.LeakyReLU()(conv2)\n",
        "  conv3 = tf.keras.layers.Conv2D(32, 4, strides=2,\n",
        "                                kernel_initializer=initializer)(conv2) \n",
        "  conv3 = tf.keras.layers.LeakyReLU()(conv3)\n",
        "  conv4 = tf.keras.layers.Conv2D(32, 4, strides=2,\n",
        "                                kernel_initializer=initializer)(conv3) \n",
        "  conv4 = tf.keras.layers.LeakyReLU()(conv4)\n",
        "\n",
        "  conv5 = tf.keras.layers.Conv2D(1, 2, strides=1,\n",
        "                                kernel_initializer=initializer)(conv4)\n",
        "  conv5 = tf.keras.layers.LeakyReLU()(conv5)\n",
        "\n",
        "  flat1 = tf.keras.layers.Flatten()(conv4)\n",
        "  dense1 = tf.keras.layers.Dense(32)(flat1)\n",
        "  dense1 = tf.keras.layers.LeakyReLU()(dense1)\n",
        "  dense2 = tf.keras.layers.Dense(16)(dense1)\n",
        "  dense2 = tf.keras.layers.LeakyReLU()(dense1) \n",
        "  dense3 = tf.keras.layers.Dense(1)(dense2) \n",
        "  dense3 = tf.keras.layers.LeakyReLU()(dense3) \n",
        "\n",
        "  return tf.keras.Model(inputs=[inp, tar], outputs=conv5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YHoUui4om-Ev",
        "colab": {}
      },
      "source": [
        "discriminator = Discriminator()\n",
        "tf.keras.utils.plot_model(discriminator, show_shapes=True, dpi=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q1Xbz5OaLj5C",
        "colab": {}
      },
      "source": [
        "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wkMNfBWlT-PV",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(disc_real_output, disc_generated_output):\n",
        "  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
        "\n",
        "  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
        "\n",
        "  total_disc_loss = real_loss + generated_loss\n",
        "\n",
        "  return (total_disc_loss*0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JCJU1o1QM1T",
        "colab_type": "text"
      },
      "source": [
        "Implementation of the perceptual loss based on the second layer of the VGG16 pre-trained network. The model is donwloaded automatically from the Tf storage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68dVKBWhOaO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16_model =tf.keras.applications.VGG16(input_shape=[128,128,3],include_top=False, weights='imagenet')\n",
        "vgg16_model.trainable=False\n",
        "\n",
        "selectedLayers = [2]\n",
        "selectedOutputs = [vgg16_model.layers[i].output for i in selectedLayers]\n",
        "vgg16_model = tf.keras.Model(vgg16_model.inputs,selectedOutputs)\n",
        "vgg16_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5i50sdYObTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perceptual_loss(out_image,out_target):\n",
        "  loss=0\n",
        "  for i in range (0,len(out_image)):\n",
        "      loss+= tf.reduce_mean(tf.abs(tf.convert_to_tensor(out_image[i])-tf.convert_to_tensor(out_target[i])))\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lbHFNexF0x6O",
        "colab": {}
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-5, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-5, beta_1=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WJnftd5sQsv6",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = '/content/drive/My Drive/MRI_data/checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RmdVsmvhPxyy",
        "colab": {}
      },
      "source": [
        "def generate_images(model, test_input, tar):\n",
        "  prediction = model(test_input, training=True)\n",
        "  plt.figure(figsize=(15,15))\n",
        "\n",
        "  diff = np.squeeze(prediction[0]) - np.squeeze(test_input[0])\n",
        "  diff2 = np.squeeze(np.squeeze(tar[0])-(np.squeeze(test_input[0])))\n",
        "  display_list = [np.squeeze(test_input[0]), np.squeeze(tar[0]), np.squeeze(prediction[0]), diff, diff2 ]\n",
        "  title = ['Input Image', 'Ground Truth', 'Predicted Image', 'Difference output-input', 'Real difference']\n",
        "\n",
        "\n",
        "  for i in range(5):\n",
        "    plt.subplot(1, 5, i+1)\n",
        "    plt.title(title[i])\n",
        "    # getting the pixel values between [0, 1] to plot it.\n",
        "    plt.imshow(display_list[i][32:96,32:96],cmap='gray')\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO_MxhhoS5h2",
        "colab_type": "text"
      },
      "source": [
        "Visualization of the initial results when the generator is inizialized with random weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8Fc4NzT-DgEx",
        "colab": {}
      },
      "source": [
        "for example_input, example_target in train_dataset.take(2):\n",
        "  generate_images(generator,example_input,example_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NLKOG55MErD0"
      },
      "source": [
        "## Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NS2GWywBbAWo",
        "colab": {}
      },
      "source": [
        "EPOCHS = 40"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xNNMDBNH12q-",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "log_dir=\"logs/\"\n",
        "summary_writer = tf.summary.create_file_writer(\n",
        "  log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KBKUV2sKXDbY",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(input_image, target, epoch):\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    gen_output = generator(input_image, training=True)\n",
        "\n",
        "    disc_real_output = discriminator([input_image, target], training=True)\n",
        "    disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
        "    \n",
        "    out_image = vgg16_model([(tf.concat((gen_output,gen_output,gen_output),axis=-1)),gen_output],training=False)\n",
        "    out_target = vgg16_model([(tf.concat((target,target,target),axis=-1)),target],training=False)\n",
        "    vgg_loss = perceptual_loss(out_image,out_target)\n",
        "\n",
        "    gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target, vgg_loss)\n",
        "    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "  generator_gradients = gen_tape.gradient(gen_total_loss,\n",
        "                                          generator.trainable_variables)\n",
        "  discriminator_gradients = disc_tape.gradient(disc_loss,\n",
        "                                               discriminator.trainable_variables)\n",
        "  discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
        "                                              discriminator.trainable_variables))\n",
        "  generator_optimizer.apply_gradients(zip(generator_gradients,\n",
        "                                          generator.trainable_variables))  \n",
        "\n",
        "  with summary_writer.as_default():\n",
        "    tf.summary.scalar('vgg_loss', vgg_loss, step=epoch)\n",
        "    tf.summary.scalar('gen_total_loss', gen_total_loss, step=epoch)\n",
        "    tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=epoch)\n",
        "    tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=epoch)\n",
        "    tf.summary.scalar('disc_loss', disc_loss, step=epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2M7LmLtGEMQJ",
        "colab": {}
      },
      "source": [
        "def fit(train_ds, epochs, test_ds):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "\n",
        "    for example_input, example_target in test_ds.take(3):\n",
        "      generate_images(generator, example_input, example_target)\n",
        "    print(\"Epoch: \", epoch)\n",
        "\n",
        "    # Train\n",
        "    for n, (input_image, target) in train_ds.enumerate():\n",
        "      print('.', end='')\n",
        "      if (n+1) % 100 == 0:\n",
        "        print()\n",
        "      train_step(input_image, target, epoch)\n",
        "    print()\n",
        "\n",
        "    # saving (checkpoint) the model every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
        "                                                        time.time()-start))\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ot22ujrlLhOd",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {log_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a1zZmKmvOH85",
        "colab": {}
      },
      "source": [
        "fit(train_dataset, EPOCHS, train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kz80bY3aQ1VZ"
      },
      "source": [
        "## Restore a model and infer new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4t4x69adQ5xb",
        "colab": {}
      },
      "source": [
        "checkpoint.restore(\"../Model/ckpt-4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpSRa2gdqFZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data_test_x(path):\n",
        "    m_image = load_nii((path+'mprage_sk.nii.gz'),mmap=True)\n",
        "    orientation = m_image.affine\n",
        "    h = m_image.header\n",
        "    image = np.squeeze(np.float32(m_image.get_fdata()))\n",
        "    image -= np.mean(image)\n",
        "    image /= np.std(image)\n",
        "\n",
        "    print(image.shape)\n",
        "    shape= np.shape(image)\n",
        "    N = np.shape(image)[0]\n",
        "    y= np.shape(image)[1]\n",
        "    z= np.shape(image)[2]\n",
        "    output = np.zeros([N,256,256,1])\n",
        "\n",
        "    for i in range(0,N):\n",
        "        image_one = image[i,:y,:z]\n",
        "        image_one=np.expand_dims(image_one,axis=2)\n",
        "        output[i,:y,:z,:]=image_one\n",
        "\n",
        "    target = np.zeros([N,256,256,1])\n",
        "\n",
        "    for i in range(0,N):\n",
        "        image_one = image[i,:y,:z]\n",
        "        image_one=np.expand_dims(image_one,axis=2)\n",
        "        target[i,:y,:z,:]=image_one\n",
        "\n",
        "    return output,target,orientation,h,shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8R0We3lqPmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data_test_y(path):\n",
        "    m_image = load_nii((path+'mprage_sk.nii.gz'),mmap=True)\n",
        "    orientation = m_image.affine\n",
        "    image = np.squeeze(np.float32(m_image.get_fdata()))\n",
        "    image -= np.mean(image)\n",
        "    image /= np.std(image)\n",
        "\n",
        "    print(image.shape)\n",
        "    N = np.shape(image)[1]\n",
        "    y= np.shape(image)[1]\n",
        "    z= np.shape(image)[2]\n",
        "    x= np.shape(image)[0]\n",
        "    output = np.zeros([N,256,256,1])\n",
        "\n",
        "    for i in range(0,N):\n",
        "        image_one = image[:x,i,:z]\n",
        "        image_one=np.expand_dims(image_one,axis=2)\n",
        "        output[i,:x,:z,:]=image_one\n",
        "\n",
        "    target = np.zeros([N,256,256,1])\n",
        "\n",
        "    for i in range(0,N):\n",
        "        image_one = image[:x,i,:z]\n",
        "        image_one=np.expand_dims(image_one,axis=2)\n",
        "        target[i,:x,:z,:]=image_one\n",
        "\n",
        "    return output,target,orientation   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a3JfjXwzGkd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data_test_z(path):\n",
        "    m_image = load_nii((path+'mprage_sk.nii.gz'),mmap=True)\n",
        "    orientation = m_image.affine\n",
        "    image = np.squeeze(np.float32(m_image.get_fdata()))\n",
        "    image -= np.mean(image)\n",
        "    image /= np.std(image)\n",
        "\n",
        "    print(image.shape)\n",
        "    N = np.shape(image)[2]\n",
        "    y= np.shape(image)[1]\n",
        "    z= np.shape(image)[2]\n",
        "    x= np.shape(image)[0]\n",
        "    output = np.zeros([N,256,256,1])\n",
        "\n",
        "    for i in range(0,N):\n",
        "        image_one = image[:x,:y,i]\n",
        "        image_one=np.expand_dims(image_one,axis=2)\n",
        "        output[i,:x,:y,:]=image_one\n",
        "\n",
        "    m_image = load_nii((path+'mprage_sk.nii.gz'),mmap=True)\n",
        "    image = np.squeeze(np.float32(m_image.get_fdata()))\n",
        "    image -= np.mean(image)\n",
        "    image /= np.std(image)\n",
        "\n",
        "    \n",
        "    target = np.zeros([N,256,256,1])\n",
        "\n",
        "    for i in range(0,N):\n",
        "        image_one = image[:x,:y,i]\n",
        "        image_one=np.expand_dims(image_one,axis=2)\n",
        "        target[i,:x,:y,:]=image_one\n",
        "\n",
        "    return output,target,orientation   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlTdLi9-PO5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 1\n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTMmtStcQ8l2",
        "colab_type": "text"
      },
      "source": [
        "The variable path_test refers to the folder where the testing dataset is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2rkXxqyvkOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_test = '../TestData/'\n",
        "for k in range (1,2):\n",
        "\n",
        "  path= path_test+str(k)+'/'\n",
        "  x,t,orien,h,shape =load_data_test_x(path)\n",
        "  test_dataset = tf.data.Dataset.from_tensor_slices((x.astype(np.float32), t.astype(np.float32)))\n",
        "  test_dataset= test_dataset.batch(BATCH_SIZE)\n",
        "  output=np.array([])\n",
        "\n",
        "  for inp, tar in test_dataset:\n",
        "    prediction = generator(inp, training=True)\n",
        "    output= np.concatenate((output,np.squeeze(prediction.numpy(),axis=0)),axis=-1) if output.size else np.squeeze(prediction.numpy(),axis=0)\n",
        "\n",
        "  output_x=np.moveaxis(output,-1,0)\n",
        "\n",
        "  x,t,orien =load_data_test_y(path)\n",
        "  test_dataset = tf.data.Dataset.from_tensor_slices((x.astype(np.float32), t.astype(np.float32)))\n",
        "  test_dataset= test_dataset.batch(BATCH_SIZE)\n",
        "  output=np.array([])\n",
        "\n",
        "  for inp, tar in test_dataset:\n",
        "    prediction = generator(inp, training=True)\n",
        "    output= np.concatenate((output,np.squeeze(prediction.numpy(),axis=0)),axis=-1) if output.size else np.squeeze(prediction.numpy(),axis=0)\n",
        "\n",
        "  output_y=np.moveaxis(output,-1,1)\n",
        "\n",
        "  x,t,orien =load_data_test_z(path)\n",
        "  test_dataset = tf.data.Dataset.from_tensor_slices((x.astype(np.float32), t.astype(np.float32)))\n",
        "  test_dataset= test_dataset.batch(BATCH_SIZE)\n",
        "  output=np.array([])\n",
        "\n",
        "  for inp, tar in test_dataset:\n",
        "    prediction = generator(inp, training=True)\n",
        "    output= np.concatenate((output,np.squeeze(prediction.numpy(),axis=0)),axis=-1) if output.size else np.squeeze(prediction.numpy(),axis=0)\n",
        "\n",
        "  output_z=output\n",
        "  x_dim=shape[0]\n",
        "  y_dim=shape[1]\n",
        "  z_dim=shape[2]  \n",
        "\n",
        "  output_f = ((output_x[:x_dim,:y_dim,:z_dim]+output_y[:x_dim,:y_dim,:z_dim]+output_z[:x_dim,:y_dim,:z_dim])/3)\n",
        "  nifti_out = nib.Nifti1Image(output_f, affine=orien,header=h)\n",
        "  nifti_out.to_filename(path+'synt.nii.gz')\n",
        "print ('Inference completed')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TZtzNLDSJX1",
        "colab_type": "text"
      },
      "source": [
        "The synthetic MP2RAGE images generated are saved in each testing subject's folder and named synt.nii.gz\n"
      ]
    }
  ]
}
